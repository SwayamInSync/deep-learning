{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection\n",
    "# Run this script to enable the datasets download\n",
    "# Reference: https://github.com/pytorch/vision/issues/1938\n",
    "\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "If you haven't seen `nn.Sequential` yet, please finish the end of the Part 2 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3119, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2981, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7005,  2.6598],\n",
      "        [-0.5403,  0.9711]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4907, 7.0745],\n",
      "        [0.2919, 0.9430]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the operation that created `y`, a power operation `PowBackward0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7fb66a728970>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autograd module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the gradients for `x` and `y` but they are empty currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3503,  1.3299],\n",
      "        [-0.2701,  0.4855]])\n",
      "tensor([[-0.3503,  1.3299],\n",
      "        [-0.2701,  0.4855]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
      "        [-0.0050, -0.0050, -0.0050,  ..., -0.0050, -0.0050, -0.0050],\n",
      "        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
      "        ...,\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
      "        [ 0.0022,  0.0022,  0.0022,  ...,  0.0022,  0.0022,  0.0022],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0088, -0.0141,  0.0258,  ...,  0.0016, -0.0079,  0.0100],\n",
      "        [ 0.0099, -0.0351, -0.0071,  ...,  0.0013, -0.0355, -0.0120],\n",
      "        [ 0.0084, -0.0041,  0.0227,  ...,  0.0270,  0.0019, -0.0305],\n",
      "        ...,\n",
      "        [-0.0122,  0.0203,  0.0020,  ...,  0.0012,  0.0150, -0.0017],\n",
      "        [ 0.0079, -0.0317, -0.0173,  ..., -0.0178,  0.0127,  0.0182],\n",
      "        [ 0.0309, -0.0275,  0.0138,  ...,  0.0303,  0.0192, -0.0212]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        [-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0031, -0.0031, -0.0031,  ..., -0.0031, -0.0031, -0.0031],\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0088, -0.0141,  0.0258,  ...,  0.0016, -0.0079,  0.0100],\n",
      "        [ 0.0100, -0.0350, -0.0071,  ...,  0.0013, -0.0355, -0.0120],\n",
      "        [ 0.0084, -0.0041,  0.0227,  ...,  0.0270,  0.0020, -0.0305],\n",
      "        ...,\n",
      "        [-0.0122,  0.0203,  0.0020,  ...,  0.0012,  0.0150, -0.0017],\n",
      "        [ 0.0080, -0.0317, -0.0172,  ..., -0.0178,  0.0127,  0.0183],\n",
      "        [ 0.0309, -0.0275,  0.0138,  ...,  0.0303,  0.0192, -0.0212]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and view the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.902354075329136\n",
      "Training loss: 0.8317925732717839\n",
      "Training loss: 0.5100187009839869\n",
      "Training loss: 0.42363458018757894\n",
      "Training loss: 0.3839636096742743\n"
     ]
    }
   ],
   "source": [
    "## Your solution here\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output,labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d0ce585ba42aaeb440d8bc31b1cfe4df4b28be41ad5aca95db481df065fbb3c"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
